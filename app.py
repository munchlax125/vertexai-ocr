from flask import Flask, request, jsonify, send_file, send_from_directory, Response
from flask_cors import CORS
import os
import tempfile
import zipfile
import uuid
from datetime import datetime
import threading
import logging
import subprocess
import json
import queue

from pdf_processor import PDFProcessor

app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)

# ë¡œê¹… ì„¤ì • (HTTP ìš”ì²­ ë¡œê·¸ ë ˆë²¨ ì¡°ì •)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Werkzeug ë¡œê¹… ë ˆë²¨ì„ WARNINGìœ¼ë¡œ ì„¤ì •í•˜ì—¬ HTTP ìš”ì²­ ë¡œê·¸ ìˆ¨ê¸°ê¸°
log = logging.getLogger('werkzeug')
log.setLevel(logging.WARNING)

# ì„¤ì •
PDF_SOURCE_FOLDER = 'pdfs'
MASKED_PDF_FOLDER = 'masked-pdfs'
MAX_WORKERS = 4
BATCH_SIZE = 50

# ì‘ì—… ìƒíƒœ ì¶”ì 
job_status = {}
job_lock = threading.Lock()

# ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ í
log_queues = {}
log_queues_lock = threading.Lock()

# í´ë” ìƒì„±
os.makedirs(PDF_SOURCE_FOLDER, exist_ok=True)
os.makedirs(MASKED_PDF_FOLDER, exist_ok=True)

# PDF í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
pdf_processor = PDFProcessor(PDF_SOURCE_FOLDER, MASKED_PDF_FOLDER, BATCH_SIZE)

def update_job_status(job_id, status, progress=0, message="", error=None, log_output=None):
    """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
    with job_lock:
        job_status[job_id] = {
            'status': status,
            'progress': progress,
            'message': message,
            'error': error,
            'log_output': log_output,
            'timestamp': datetime.now().isoformat()
        }

def add_log_to_queue(job_id, log_line):
    """ì‹¤ì‹œê°„ ë¡œê·¸ íì— ìƒˆ ë¡œê·¸ ì¶”ê°€"""
    with log_queues_lock:
        if job_id in log_queues:
            try:
                log_queues[job_id].put_nowait(log_line)
            except queue.Full:
                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì˜¤ë˜ëœ ë¡œê·¸ ì œê±°
                try:
                    log_queues[job_id].get_nowait()
                    log_queues[job_id].put_nowait(log_line)
                except queue.Empty:
                    pass

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€ - index.html ë°˜í™˜"""
    return send_from_directory('.', 'index.html')

@app.route('/<path:filename>')
def static_files(filename):
    """ì •ì  íŒŒì¼ ì„œë¹™ (CSS, JS ë“±)"""
    return send_from_directory('.', filename)

@app.route('/scan-pdfs', methods=['GET'])
def scan_pdfs():
    """pdfs í´ë”ì˜ íŒŒì¼ ëª©ë¡ ìŠ¤ìº”"""
    try:
        result = pdf_processor.scan_pdf_files()
        return jsonify({
            'success': True,
            'files': result['files'],
            'count': result['count'],
            'total_size': result['total_size'],
            'folder': PDF_SOURCE_FOLDER
        })
    except Exception as e:
        return jsonify({'error': f'í´ë” ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/mask-pdfs', methods=['POST'])
def mask_pdfs():
    """pdfs í´ë”ì˜ íŒŒì¼ë“¤ì„ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬"""
    try:
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        update_job_status(job_id, 'pending', 0, 'ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘')
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘
        def background_task():
            def status_callback(status, progress, message):
                update_job_status(job_id, status, progress, message)
            
            try:
                result = pdf_processor.process_masking(status_callback)
                # ê²°ê³¼ë¥¼ job_statusì— ì €ì¥
                with job_lock:
                    job_status[job_id]['result'] = result
            except Exception as e:
                update_job_status(job_id, 'failed', 0, '', str(e))
        
        thread = threading.Thread(target=background_task)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': 'ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'source_folder': PDF_SOURCE_FOLDER,
            'target_folder': MASKED_PDF_FOLDER
        })
        
    except Exception as e:
        return jsonify({'error': f'ë§ˆìŠ¤í‚¹ ì‘ì—… ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

def run_ocr_with_realtime_output(job_id):
    """ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìº¡ì²˜í•˜ë©´ì„œ OCR ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ì‹œê°„ ì œí•œ ì—†ìŒ)"""
    try:
        update_job_status(job_id, 'running', 10, 'Gemini OCR ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...')
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ í ìƒì„±
        with log_queues_lock:
            log_queues[job_id] = queue.Queue(maxsize=1000)
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONUNBUFFERED'] = '1'
        
        # í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (timeout ì œê±°)
        process = subprocess.Popen(
            ['python', 'gemini-pdf-ocr-genai.py'], 
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            env=env,
            bufsize=1,
            universal_newlines=True
        )
        
        output_lines = []
        
        # ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ ì½ê¸°
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                line = output.strip()
                if line:  # ë¹ˆ ì¤„ ì œì™¸
                    output_lines.append(line)
                    
                    # ì‹¤ì‹œê°„ ë¡œê·¸ íì— ì¶”ê°€ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ëœ ì›ë³¸ ê·¸ëŒ€ë¡œ)
                    add_log_to_queue(job_id, line)
                    
                    # ì§„í–‰ë¥  ê³„ì‚° (íŒŒì¼ë³„ ì²˜ë¦¬ ë‹¨ê³„ ê¸°ë°˜)
                    progress = 20
                    if 'ì²˜ë¦¬ ì‹œì‘' in line:
                        progress = min(30, 20 + len(output_lines) // 10)
                    elif 'OCR ë¶„ì„ ì‹œì‘' in line:
                        progress = min(50, 30 + len(output_lines) // 8)
                    elif 'AI ë¶„ì„ ì¤‘' in line:
                        progress = min(70, 50 + len(output_lines) // 6)
                    elif 'êµ¬ê¸€ì‹œíŠ¸ ì—…ë¡œë“œ' in line:
                        progress = min(85, 70 + len(output_lines) // 4)
                    elif 'ì™„ì „ ì²˜ë¦¬ ì™„ë£Œ' in line:
                        progress = min(95, 85 + len(output_lines) // 3)
                    elif 'ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ' in line:
                        progress = 100
                    elif 'ì—°ê²°' in line or 'ì´ˆê¸°í™”' in line:
                        progress = 15
                    
                    # ì£¼ìš” ë©”ì‹œì§€ë§Œ statusì— í‘œì‹œ
                    status_message = "OCR ì²˜ë¦¬ ì§„í–‰ ì¤‘..."
                    if any(keyword in line for keyword in 
                        ['ì²˜ë¦¬ ì™„ë£Œ', 'ì—…ë¡œë“œ ì™„ë£Œ', 'ì‹œì‘', 'ì—°ê²°', 'ì„±ê³µ', 'ì‹¤íŒ¨', 'ì˜¤ë¥˜', 'ì™„ë£Œ']):
                        status_message = line.replace('[', '').replace(']', '').split('] ')[-1] if '] ' in line else line
                    
                    # ìµœê·¼ ë¡œê·¸ë§Œ statusì— í¬í•¨ (ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì€ ë³„ë„)
                    recent_logs = '\n'.join(output_lines[-50:])  # ìµœê·¼ 50ì¤„ë§Œ
                    update_job_status(job_id, 'running', progress, status_message, log_output=recent_logs)
        
        # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸° (ë¬´ì œí•œ)
        return_code = process.wait()
        
        # ì „ì²´ ì¶œë ¥ ê²°í•©
        full_output = '\n'.join(output_lines)
        
        if return_code == 0:
            completion_msg = "ğŸ‰ OCR ì²˜ë¦¬ê°€ ì™„ì „íˆ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
            add_log_to_queue(job_id, f"[{datetime.now().strftime('%H:%M:%S')}] {completion_msg}")
            update_job_status(job_id, 'completed', 100, 'OCR ì²˜ë¦¬ ì™„ë£Œ', log_output=full_output)
            with job_lock:
                job_status[job_id]['result'] = {
                    'output': full_output,
                    'success': True
                }
        else:
            error_msg = "âŒ OCR ì²˜ë¦¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            add_log_to_queue(job_id, f"[{datetime.now().strftime('%H:%M:%S')}] {error_msg}")
            update_job_status(job_id, 'failed', 0, 'OCR ì²˜ë¦¬ ì‹¤íŒ¨', full_output, log_output=full_output)
                    
    except Exception as e:
        error_msg = f"OCR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
        add_log_to_queue(job_id, f"[{datetime.now().strftime('%H:%M:%S')}] âŒ {error_msg}")
        update_job_status(job_id, 'failed', 0, error_msg, str(e))
        logger.error(error_msg)
    finally:
        # ë¡œê·¸ í ì •ë¦¬
        with log_queues_lock:
            if job_id in log_queues:
                del log_queues[job_id]

@app.route('/run-gemini-ocr-async', methods=['POST'])
def run_gemini_ocr_async():
    """ë¹„ë™ê¸° Gemini OCR ì²˜ë¦¬"""
    try:
        if not os.path.exists(MASKED_PDF_FOLDER):
            return jsonify({'error': f'"{MASKED_PDF_FOLDER}" í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        masked_files = [f for f in os.listdir(MASKED_PDF_FOLDER) if f.lower().endswith('.pdf')]
        if not masked_files:
            return jsonify({'error': f'"{MASKED_PDF_FOLDER}" í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        update_job_status(job_id, 'pending', 0, f'{len(masked_files)}ê°œ íŒŒì¼ OCR ì²˜ë¦¬ ëŒ€ê¸° ì¤‘')
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤ì‹œê°„ ì¶œë ¥ê³¼ í•¨ê»˜ OCR ì‹¤í–‰
        thread = threading.Thread(target=run_ocr_with_realtime_output, args=(job_id,))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': f'{len(masked_files)}ê°œ íŒŒì¼ OCR ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ì‹œê°„ ì œí•œ ì—†ìŒ)',
            'source_folder': MASKED_PDF_FOLDER
        })
        
    except Exception as e:
        return jsonify({'error': f'OCR ì‘ì—… ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/extract-info', methods=['POST'])
def extract_personal_info():
    """ê°œì¸ì •ë³´ ì¶”ì¶œ"""
    try:
        personal_info = pdf_processor.extract_personal_info()
        
        return jsonify({
            'success': True,
            'personal_info': personal_info,
            'total_extracted': len(personal_info),
            'source_folder': PDF_SOURCE_FOLDER
        })
        
    except Exception as e:
        return jsonify({'error': f'ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/job-status/<job_id>')
def get_job_status(job_id):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    with job_lock:
        if job_id not in job_status:
            return jsonify({'error': 'ì‘ì—… IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        return jsonify(job_status[job_id])

@app.route('/stream-logs/<job_id>')
def stream_logs(job_id):
    """ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° (Server-Sent Events)"""
    def generate():
        # ê¸°ì¡´ ë¡œê·¸ê°€ ìˆë‹¤ë©´ ë¨¼ì € ì „ì†¡
        with job_lock:
            if job_id in job_status and job_status[job_id].get('log_output'):
                existing_logs = job_status[job_id]['log_output'].split('\n')
                for log_line in existing_logs:
                    if log_line.strip():
                        yield f"data: {json.dumps({'type': 'log', 'message': log_line})}\n\n"
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼
        timeout_count = 0
        max_timeout = 300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        
        while timeout_count < max_timeout:
            try:
                with log_queues_lock:
                    if job_id not in log_queues:
                        # ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                        with job_lock:
                            if job_id in job_status:
                                status = job_status[job_id]['status']
                                if status in ['completed', 'failed']:
                                    yield f"data: {json.dumps({'type': 'status', 'status': status})}\n\n"
                                    break
                        timeout_count += 1
                        time.sleep(1)
                        continue
                    
                    log_queue = log_queues[job_id]
                
                try:
                    # 0.5ì´ˆ ëŒ€ê¸°ë¡œ ìƒˆ ë¡œê·¸ í™•ì¸
                    log_line = log_queue.get(timeout=0.5)
                    yield f"data: {json.dumps({'type': 'log', 'message': log_line})}\n\n"
                    timeout_count = 0  # ë¡œê·¸ë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ íƒ€ì„ì•„ì›ƒ ë¦¬ì…‹
                except queue.Empty:
                    timeout_count += 1
                    continue
                    
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
                break
        
        yield f"data: {json.dumps({'type': 'close'})}\n\n"
    
    return Response(generate(), mimetype='text/plain')

import time

@app.route('/download-masked')
def download_masked_files():
    """ë§ˆìŠ¤í‚¹ëœ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        if not os.path.exists(MASKED_PDF_FOLDER):
            return jsonify({'error': f'"{MASKED_PDF_FOLDER}" í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        masked_files = [f for f in os.listdir(MASKED_PDF_FOLDER) if f.endswith('.pdf')]
        
        if not masked_files:
            return jsonify({'error': 'ë‹¤ìš´ë¡œë“œí•  ë§ˆìŠ¤í‚¹ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        zip_path = os.path.join(tempfile.gettempdir(), 
                               f'masked_files_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip')
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for filename in masked_files:
                file_path = os.path.join(MASKED_PDF_FOLDER, filename)
                zipf.write(file_path, filename)
            
            # ë§¤í•‘ íŒŒì¼ë„ í¬í•¨
            mapping_path = os.path.join(MASKED_PDF_FOLDER, 'file_mapping.json')
            if os.path.exists(mapping_path):
                zipf.write(mapping_path, 'file_mapping.json')
        
        return send_file(
            zip_path,
            as_attachment=True,
            download_name=f'masked_pdfs_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip',
            mimetype='application/zip'
        )
        
    except Exception as e:
        return jsonify({'error': f'ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/health')
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ - Vertex AI ë²„ì „"""
    
    # í´ë” ìƒíƒœ í™•ì¸
    pdfs_exists = os.path.exists(PDF_SOURCE_FOLDER)
    pdfs_count = len([f for f in os.listdir(PDF_SOURCE_FOLDER) if f.endswith('.pdf')]) if pdfs_exists else 0
    
    masked_exists = os.path.exists(MASKED_PDF_FOLDER)
    masked_count = len([f for f in os.listdir(MASKED_PDF_FOLDER) if f.endswith('.pdf')]) if masked_exists else 0
    
    # Vertex AI í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    vertex_ai_config = {
        'project_id': os.getenv('GOOGLE_CLOUD_PROJECT'),
        'location': os.getenv('GOOGLE_CLOUD_LOCATION', 'us-central1'),
        'credentials_path': os.getenv('GOOGLE_APPLICATION_CREDENTIALS'),
        'credentials_exists': os.path.exists(os.getenv('GOOGLE_APPLICATION_CREDENTIALS', '')) if os.getenv('GOOGLE_APPLICATION_CREDENTIALS') else False
    }
    
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '4.0.0 (Vertex AI)',
        'api_type': 'Vertex AI',
        'vertex_ai': vertex_ai_config,
        'folders': {
            'pdfs': {
                'exists': pdfs_exists,
                'count': pdfs_count,
                'path': PDF_SOURCE_FOLDER
            },
            'masked_pdfs': {
                'exists': masked_exists,
                'count': masked_count,
                'path': MASKED_PDF_FOLDER
            }
        },
        'max_workers': MAX_WORKERS,
        'batch_size': BATCH_SIZE
    })

if __name__ == '__main__':
    print("ğŸš€ PDF í†µí•© ì²˜ë¦¬ ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“‚ ì›ë³¸ PDF í´ë”: {PDF_SOURCE_FOLDER}")
    print(f"ğŸ“‚ ë§ˆìŠ¤í‚¹ í´ë”: {MASKED_PDF_FOLDER}")
    print(f"âš™ï¸ ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬: {MAX_WORKERS} ìŠ¤ë ˆë“œ")
    print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE} íŒŒì¼")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    
    app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)